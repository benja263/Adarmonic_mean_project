{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# interactive widget imports\n",
    "import ipywidgets as wg\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "# data handling modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# plotting imports\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly\n",
    "from plotly import tools\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "plotly.tools.set_credentials_file(username='Flavioh', api_key='GogTSHQAuhgi5p724TsF')\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "# web scraping\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# other helpers and suppress warnings\n",
    "from helpers import *\n",
    "from timeline_helpers import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", 'This pattern has match groups')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "df = pd.read_csv('../generated/FINAL_DF_WITH_TOPICS.csv', index_col=0)\n",
    "df['publish_date'] = pd.to_datetime(df['publish_date'])\n",
    "df = df[(df.publish_date > '2016-09-01') & (df.publish_date < '2016-11-10')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filtered = df[['publish_date', 'followers', 'following', 'author', 'like_count', 'topic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filtered.topic.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "def count_topic(topic, df):\n",
    "    \"\"\"The function takes in a language as a DEFINE_string\n",
    "    and goes through a dataframe that has one column named\n",
    "    topic and another one that has publish_date. It then\n",
    "    groups the tweets by month and returns the sum of the\n",
    "    tweets during the time period\"\"\"\n",
    "\n",
    "    filt = df[df.topic == topic].copy()\n",
    "    filt['topic_num'] = filt.topic.map({topic:1})\n",
    "    return filt.groupby(pd.Grouper(key='publish_date', freq='1D')).sum()\n",
    "\n",
    "def trace_generator_topic(topic_df):\n",
    "    \"\"\"This function generates the data that will be used\n",
    "    as input for the iplot function. It prepares the labels\n",
    "    from the index\"\"\"\n",
    "    data = []\n",
    "    for topic in topic_df.topic.value_counts().index.values:\n",
    "        filtered=count_topic(topic, topic_df)\n",
    "        strd = pd.Series(filtered.index.strftime('%Y-%m-%d %H-%M-%S'))\n",
    "        xlabels = list(strd.apply(lambda x: x[0:10]))\n",
    "        trace = go.Scatter(x=xlabels,\n",
    "                            y=filtered.topic_num.values,\n",
    "                            fill='tozeroy',\n",
    "                            mode= 'none',\n",
    "                            name=topic)\n",
    "        data.append(trace)\n",
    "\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = trace_generator_topic(data_filtered)\n",
    "layout = do_layout('Date', 'Number of Tweets', 'Topic as a Function of Time')\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examination of Top Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract top 10 posting authors\n",
    "top_authors = data_filtered.author.value_counts()[0:10]\n",
    "\n",
    "# Filter data frame for them\n",
    "###### testing with screamymonkey\n",
    "\n",
    "topauthors = data_filtered[data_filtered.author.isin(top_authors.index.values)]\n",
    "test = topauthors.copy()\n",
    "# test = data_filtered[data_filtered.author == 'WORLDOFHASHTAGS']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data1 = trace_generator_topic(test)\n",
    "layout = do_layout('Date', 'Number of Tweets', 'Topic for Top 10 Authors Over Time')\n",
    "fig = go.Figure(data=data1, layout=layout)\n",
    "py.iplot(fig, filename='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out follower counts for top 10 hashtaggers\n",
    "\n",
    "group_followers = test.groupby([pd.Grouper(key='publish_date', freq='1D'), 'author'])['followers'].max().groupby(level=0).sum()\n",
    "\n",
    "######\n",
    "\n",
    "test['tweet_counts'] = np.ones(test.shape[0])\n",
    "\n",
    "group_likes =test.groupby([pd.Grouper(key='publish_date', freq='1D'),\n",
    "                                 'author'])['like_count'].max().groupby(level=0).sum()\n",
    "\n",
    "group_following =test.groupby([pd.Grouper(key='publish_date', freq='1D'),\n",
    "                                 'author'])['following'].max().groupby(level=0).sum()\n",
    "group_authors_time = pd.DataFrame({'followers': group_followers.values,\n",
    "                                   'following': group_following.values},\n",
    "                                  index=group_followers.index.values)\n",
    "\n",
    " \n",
    "# group by month\n",
    "general_timeline = test.groupby(pd.Grouper(key='publish_date', freq='1D')).sum()\n",
    "# construct labels\n",
    "xlabels = list(pd.Series(group_authors_time.index.strftime(\n",
    "    '%Y-%m-%d %H-%M-%S')).apply(lambda x: x[0:10]))\n",
    "data = []\n",
    "\n",
    "for col in group_authors_time:\n",
    "    filtered = group_authors_time[col].copy()\n",
    "    trace = go.Scatter(x=xlabels, y=filtered.values, name=col, \n",
    "                       fill='tozeroy', mode='lines')\n",
    "    data.append(trace)\n",
    "\n",
    "filtered = general_timeline['tweet_counts'].copy()\n",
    "trace=go.Scatter(x=xlabels, y=filtered.values, marker = {'color' : '#00AA00'}, name='Tweet Counts', fill='tozeroy', mode='lines')\n",
    "data.append(trace)\n",
    "trace = go.Scatter(x=xlabels, y=group_likes.values, marker = {'color' : '#FF2200'}, name='Tweet Likes', fill='tozeroy', mode='lines')\n",
    "data.append(trace)\n",
    "\n",
    "\n",
    "\n",
    "# Create plots for following, followers, updates, tweet_counts\n",
    "\n",
    "fig = tools.make_subplots(rows=3, cols=1)\n",
    "\n",
    "fig.append_trace(data[0], 1, 1)\n",
    "fig.append_trace(data[1], 1, 1)\n",
    "fig.append_trace(data[2], 2, 1)\n",
    "fig.append_trace(data[3], 3, 1)\n",
    "\n",
    "fig['layout'].update(height=600, width=800, title='General Trends Across Time')\n",
    "py.iplot(fig, filename='y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation values\n",
    "\n",
    "# Creating dataframe of entries for correlation statistics\n",
    "corr_df = pd.DataFrame({'Followers': group_followers.values, 'Likes': group_likes.values,\n",
    "                       'Following': group_following.values})\n",
    "corr_df.index = xlabels                        \n",
    "\n",
    "topics = data_filtered.topic.value_counts().index.values\n",
    "for topic in topics:\n",
    "    x = count_topic(topic, topauthors)\n",
    "    corr_df = corr_df.join(x[['topic_num']], how='outer', rsuffix=topic)\n",
    "\n",
    "corr_df.columns = ['Followers', 'Likes', 'Following', *topics]\n",
    "\n",
    "corr_df.fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corr_df.iloc[0:200].Sports.corr(corr_df.iloc[0:200].Followers))\n",
    "print(corr_df.iloc[0:200]['w'].corr(corr_df.iloc[0:200].Followers))\n",
    "print(corr_df.iloc[0:200]['Entertainment'].corr(corr_df.iloc[0:200].Followers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corr_df.iloc[0:200].corr().iloc[:,0])\n",
    "print(corr_df.iloc[-100:].corr().iloc[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Swing State Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "\n",
    "# Scrape wikipedia table for american cities and states\n",
    "website = requests.get('https://en.wikipedia.org/wiki/List_of_largest_cities_of_U.S._states_and_territories_by_population').text\n",
    "soup = BeautifulSoup(website,'html.parser')\n",
    "\n",
    "My_table = soup.find('table',{'class':'wikitable sortable'})\n",
    "\n",
    "links = My_table.find_all('a')\n",
    "\n",
    "places = []\n",
    "for link in links:\n",
    "    places.append(link.get('title'))\n",
    "    \n",
    "city_clean = list(filter(None.__ne__, places)) # Drop None values\n",
    "cities = {}\n",
    "\n",
    "\n",
    "for entry in city_clean:\n",
    "    split=entry.split(', ')\n",
    "    if len(split) == 1:\n",
    "        cities[split[0]] = []\n",
    "    else:\n",
    "        if split[1] in cities.keys():\n",
    "            cities[split[1]].append(split[0]) \n",
    "state_n_city = []\n",
    "for state in cities.keys():\n",
    "    state_list = []\n",
    "    state_cities = cities[state]\n",
    "    for city in state_cities:\n",
    "        state_list.append(city + '|' + city.lower())\n",
    "    state_list.append(state + '|' + state.lower())\n",
    "    state_list = '|'.join(state_list)\n",
    "    state_n_city.append([state, state_list])\n",
    "    \n",
    "state_n_city_dict = {}\n",
    "for state in state_n_city:\n",
    "    state_n_city_dict[state[0]] = state[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Alabama': 'Birmingham|birmingham|Montgomery|montgomery|Huntsville|huntsville|Mobile|mobile|Tuscaloosa|tuscaloosa|Alabama|alabama',\n",
       " 'Alaska': 'Anchorage|anchorage|Fairbanks|fairbanks|Juneau|juneau|Sitka|sitka|Ketchikan|ketchikan|Alaska|alaska',\n",
       " 'American Samoa': \"Tafuna|tafuna|Nu'uuli|nu'uuli|Pava'ia'i|pava'ia'i|American Samoa|american samoa\",\n",
       " 'Pago Pago': 'Pago Pago|pago pago',\n",
       " \"'Ili'ili\": \"'Ili'ili|'ili'ili\",\n",
       " 'Arizona': 'Phoenix|phoenix|Tucson|tucson|Mesa|mesa|Chandler|chandler|Glendale|glendale|Arizona|arizona',\n",
       " 'Arkansas': 'Little Rock|little rock|Fort Smith|fort smith|Fayetteville|fayetteville|Springdale|springdale|Jonesboro|jonesboro|Arkansas|arkansas',\n",
       " 'California': 'San Jose|san jose|Fresno|fresno|Sacramento|sacramento|California|california',\n",
       " 'Los Angeles': 'Los Angeles|los angeles',\n",
       " 'San Diego': 'San Diego|san diego',\n",
       " 'San Francisco': 'San Francisco|san francisco',\n",
       " 'Colorado': 'Colorado Springs|colorado springs|Aurora|aurora|Fort Collins|fort collins|Lakewood|lakewood|Colorado|colorado',\n",
       " 'Denver': 'Denver|denver',\n",
       " 'Connecticut': 'Bridgeport|bridgeport|New Haven|new haven|Stamford|stamford|Hartford|hartford|Waterbury|waterbury|Connecticut|connecticut',\n",
       " 'Delaware': 'Wilmington|wilmington|Dover|dover|Newark|newark|Middletown|middletown|Smyrna|smyrna|Delaware|delaware',\n",
       " 'Florida': 'Jacksonville|jacksonville|Miami|miami|Tampa|tampa|Orlando|orlando|St. Petersburg|st. petersburg|Tallahassee|tallahassee|Florida|florida',\n",
       " 'Georgia (U.S. state)': 'Georgia (U.S. state)|georgia (u.s. state)',\n",
       " 'Atlanta': 'Atlanta|atlanta',\n",
       " 'Guam': 'Yigo|yigo|Tamuning|tamuning|Mangilao|mangilao|Barrigada|barrigada|Guam|guam',\n",
       " 'Dededo': 'Dededo|dededo',\n",
       " 'Hagåtña': 'Hagåtña|hagåtña',\n",
       " 'Hawaii': 'Hilo|hilo|Kapolei|kapolei|Kaneohe|kaneohe|Hawaii|hawaii',\n",
       " 'Honolulu': 'Honolulu|honolulu',\n",
       " 'Idaho': 'Boise|boise|Meridian|meridian|Nampa|nampa|Idaho Falls|idaho falls|Pocatello|pocatello|Idaho|idaho',\n",
       " 'Illinois': 'Aurora|aurora|Rockford|rockford|Joliet|joliet|Naperville|naperville|Springfield|springfield|Illinois|illinois',\n",
       " 'Chicago': 'Chicago|chicago',\n",
       " 'Indiana': 'Fort Wayne|fort wayne|Evansville|evansville|South Bend|south bend|Carmel|carmel|Indiana|indiana',\n",
       " 'Indianapolis': 'Indianapolis|indianapolis',\n",
       " 'Iowa': 'Des Moines|des moines|Cedar Rapids|cedar rapids|Davenport|davenport|Sioux City|sioux city|Iowa City|iowa city|Iowa|iowa',\n",
       " 'Kansas': 'Wichita|wichita|Overland Park|overland park|Kansas City|kansas city|Olathe|olathe|Topeka|topeka|Kansas|kansas',\n",
       " 'Kentucky': 'Louisville|louisville|Lexington|lexington|Bowling Green|bowling green|Owensboro|owensboro|Covington|covington|Frankfort|frankfort|Kentucky|kentucky',\n",
       " 'Louisiana': 'Shreveport|shreveport|Lafayette|lafayette|Lake Charles|lake charles|Louisiana|louisiana',\n",
       " 'New Orleans': 'New Orleans|new orleans',\n",
       " 'Baton Rouge': 'Baton Rouge|baton rouge',\n",
       " 'Maine': 'Portland|portland|Lewiston|lewiston|Bangor|bangor|South Portland|south portland|Auburn|auburn|Augusta|augusta|Maine|maine',\n",
       " 'Maryland': 'Frederick|frederick|Rockville|rockville|Gaithersburg|gaithersburg|Bowie|bowie|Annapolis|annapolis|Maryland|maryland',\n",
       " 'Baltimore': 'Baltimore|baltimore',\n",
       " 'Massachusetts': 'Worcester|worcester|Springfield|springfield|Lowell|lowell|Cambridge|cambridge|Massachusetts|massachusetts',\n",
       " 'Boston': 'Boston|boston',\n",
       " 'Michigan': 'Grand Rapids|grand rapids|Warren|warren|Sterling Heights|sterling heights|Ann Arbor|ann arbor|Lansing|lansing|Michigan|michigan',\n",
       " 'Detroit': 'Detroit|detroit',\n",
       " 'Minnesota': 'St. Paul|st. paul|Rochester|rochester|Bloomington|bloomington|Duluth|duluth|Minnesota|minnesota',\n",
       " 'Minneapolis': 'Minneapolis|minneapolis',\n",
       " 'Mississippi': 'Jackson|jackson|Gulfport|gulfport|Southaven|southaven|Hattiesburg|hattiesburg|Biloxi|biloxi|Mississippi|mississippi',\n",
       " 'Missouri': 'Kansas City|kansas city|Springfield|springfield|Independence|independence|Columbia|columbia|Jefferson City|jefferson city|Missouri|missouri',\n",
       " 'St. Louis': 'St. Louis|st. louis',\n",
       " 'Montana': 'Billings|billings|Missoula|missoula|Great Falls|great falls|Bozeman|bozeman|Butte|butte|Helena|helena|Montana|montana',\n",
       " 'Nebraska': 'Omaha|omaha|Lincoln|lincoln|Bellevue|bellevue|Grand Island|grand island|Kearney|kearney|Nebraska|nebraska',\n",
       " 'Nevada': 'Henderson|henderson|Reno|reno|North Las Vegas|north las vegas|Sparks|sparks|Carson City|carson city|Nevada|nevada',\n",
       " 'Las Vegas': 'Las Vegas|las vegas',\n",
       " 'New Hampshire': 'Manchester|manchester|Nashua|nashua|Concord|concord|Derry|derry|Rochester|rochester|New Hampshire|new hampshire',\n",
       " 'New Jersey': 'Newark|newark|Jersey City|jersey city|Paterson|paterson|Elizabeth|elizabeth|Edison|edison|Trenton|trenton|New Jersey|new jersey',\n",
       " 'New Mexico': 'Albuquerque|albuquerque|Las Cruces|las cruces|Santa Fe|santa fe|Roswell|roswell|New Mexico|new mexico',\n",
       " 'Rio Rancho': 'Rio Rancho|rio rancho',\n",
       " 'New York (state)': 'New York (state)|new york (state)',\n",
       " 'New York City': 'New York City|new york city',\n",
       " 'North Carolina': 'Charlotte|charlotte|Raleigh|raleigh|Greensboro|greensboro|Durham|durham|Winston-Salem|winston-salem|North Carolina|north carolina',\n",
       " 'North Dakota': 'Fargo|fargo|Bismarck|bismarck|Grand Forks|grand forks|Minot|minot|West Fargo|west fargo|North Dakota|north dakota',\n",
       " 'Northern Mariana Islands': 'Northern Mariana Islands|northern mariana islands',\n",
       " 'Saipan': 'Saipan|saipan',\n",
       " 'Tinian Municipality': 'Tinian Municipality|tinian municipality',\n",
       " 'Rota (island)': 'Rota (island)|rota (island)',\n",
       " 'Northern Islands Municipality': 'Northern Islands Municipality|northern islands municipality',\n",
       " 'Ohio': 'Columbus|columbus|Toledo|toledo|Akron|akron|Ohio|ohio',\n",
       " 'Cleveland': 'Cleveland|cleveland',\n",
       " 'Cincinnati': 'Cincinnati|cincinnati',\n",
       " 'Oklahoma': 'Tulsa|tulsa|Norman|norman|Broken Arrow|broken arrow|Lawton|lawton|Oklahoma|oklahoma',\n",
       " 'Oklahoma City': 'Oklahoma City|oklahoma city',\n",
       " 'Oregon': 'Portland|portland|Salem|salem|Eugene|eugene|Gresham|gresham|Hillsboro|hillsboro|Oregon|oregon',\n",
       " 'Pennsylvania': 'Allentown|allentown|Erie|erie|Reading|reading|Harrisburg|harrisburg|Pennsylvania|pennsylvania',\n",
       " 'Philadelphia': 'Philadelphia|philadelphia',\n",
       " 'Pittsburgh': 'Pittsburgh|pittsburgh',\n",
       " 'Puerto Rico': 'San Juan|san juan|Bayamón|bayamón|Carolina|carolina|Ponce|ponce|Caguas|caguas|Puerto Rico|puerto rico',\n",
       " 'Rhode Island': 'Providence|providence|Warwick|warwick|Cranston|cranston|Pawtucket|pawtucket|East Providence|east providence|Rhode Island|rhode island',\n",
       " 'South Carolina': 'Columbia|columbia|Charleston|charleston|North Charleston|north charleston|Mount Pleasant|mount pleasant|Rock Hill|rock hill|South Carolina|south carolina',\n",
       " 'South Dakota': 'Sioux Falls|sioux falls|Rapid City|rapid city|Aberdeen|aberdeen|Brookings|brookings|Watertown|watertown|Pierre|pierre|South Dakota|south dakota',\n",
       " 'Tennessee': 'Nashville|nashville|Memphis|memphis|Knoxville|knoxville|Clarksville|clarksville|Tennessee|tennessee',\n",
       " 'Chattanooga': 'Chattanooga|chattanooga',\n",
       " 'Texas': 'Austin|austin|Fort Worth|fort worth|Texas|texas',\n",
       " 'Houston': 'Houston|houston',\n",
       " 'San Antonio': 'San Antonio|san antonio',\n",
       " 'Dallas': 'Dallas|dallas',\n",
       " 'Utah': 'West Valley City|west valley city|Provo|provo|Orem|orem|Utah|utah',\n",
       " 'Salt Lake City': 'Salt Lake City|salt lake city',\n",
       " 'West Jordan': 'West Jordan|west jordan',\n",
       " 'Vermont': 'Burlington|burlington|Essex|essex|South Burlington|south burlington|Rutland (city)|rutland (city)|Barre (city)|barre (city)|Montpelier|montpelier|Vermont|vermont',\n",
       " 'United States Virgin Islands': 'United States Virgin Islands|united states virgin islands',\n",
       " 'U.S. Virgin Islands': 'Charlotte Amalie|charlotte amalie|Sion Farm|sion farm|U.S. Virgin Islands|u.s. virgin islands',\n",
       " 'Districts and sub-districts of the United States Virgin Islands': 'Districts and sub-districts of the United States Virgin Islands|districts and sub-districts of the united states virgin islands',\n",
       " 'Virginia': 'Virginia Beach|virginia beach|Norfolk|norfolk|Chesapeake|chesapeake|Richmond|richmond|Newport News|newport news|Virginia|virginia',\n",
       " 'Washington (state)': 'Washington (state)|washington (state)',\n",
       " 'Seattle': 'Seattle|seattle',\n",
       " 'West Virginia': 'Charleston|charleston|Huntington|huntington|Morgantown|morgantown|Parkersburg|parkersburg|Wheeling|wheeling|West Virginia|west virginia',\n",
       " 'Wisconsin': 'Madison|madison|Green Bay|green bay|Kenosha|kenosha|Racine|racine|Wisconsin|wisconsin',\n",
       " 'Milwaukee': 'Milwaukee|milwaukee',\n",
       " 'Wyoming': 'Cheyenne|cheyenne|Casper|casper|Laramie|laramie|Gillette|gillette|Rock Springs|rock springs|Wyoming|wyoming'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_n_city_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load old data set\n",
    "\n",
    "election_month = pd.read_csv('../generated/onemonth_dataset.csv', index_col=0)\n",
    "election_month['publish_date'] = pd.to_datetime(election_month['publish_date'])\n",
    "election_month = election_month[election_month.language == 'English']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "election_month = election_month[['author', 'content', 'publish_date', 'followers', 'following', 'topic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "election_month['value'] = np.ones(election_month.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "swing_states = ['Colorado',\n",
    "               'Florida',\n",
    "               'Iowa',\n",
    "               'Michigan',\n",
    "               'Nevada',\n",
    "               'New Hampshire',\n",
    "               'North Carolina',\n",
    "               'Ohio',\n",
    "               'Pennsylvania',\n",
    "               'Virginia',\n",
    "               'Wisconsin',\n",
    "               'Texas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colorado\n",
      "topic\n",
      "Anti-Islam            1.574803\n",
      "Anti-Trump            2.362205\n",
      "Black Support        21.259843\n",
      "Crime                 5.511811\n",
      "Entertainment         4.724409\n",
      "Foreign Countries     0.787402\n",
      "Health               11.811024\n",
      "Sports               13.385827\n",
      "Trump Support        38.582677\n",
      "Name: value, dtype: float64\n",
      "Florida\n",
      "topic\n",
      "Anti-Islam            1.831129\n",
      "Anti-Trump            4.577823\n",
      "Black Support        13.530010\n",
      "Crime                 1.322482\n",
      "Entertainment         8.443540\n",
      "Foreign Countries     1.525941\n",
      "Health                4.476094\n",
      "Patriot               1.322482\n",
      "Sports               22.278739\n",
      "Trump Support        40.691760\n",
      "Name: value, dtype: float64\n",
      "Iowa\n",
      "topic\n",
      "Anti-Islam        1.550388\n",
      "Anti-Trump        3.875969\n",
      "Black Support    25.581395\n",
      "Crime             3.875969\n",
      "Entertainment     1.550388\n",
      "Health            2.325581\n",
      "Patriot           1.550388\n",
      "Sports           10.852713\n",
      "Trump Support    48.837209\n",
      "Name: value, dtype: float64\n",
      "Michigan\n",
      "topic\n",
      "Anti-Islam            0.342466\n",
      "Anti-Trump            1.369863\n",
      "Black Support        11.986301\n",
      "Crime                 0.342466\n",
      "Entertainment        38.698630\n",
      "Foreign Countries     0.342466\n",
      "Health                7.191781\n",
      "Sports               11.643836\n",
      "Trump Support        28.082192\n",
      "Name: value, dtype: float64\n",
      "Nevada\n",
      "topic\n",
      "Anti-Islam            1.593625\n",
      "Anti-Trump            5.179283\n",
      "Black Support        19.521912\n",
      "Crime                 2.390438\n",
      "Entertainment         7.968127\n",
      "Foreign Countries     0.796813\n",
      "Health                6.374502\n",
      "Patriot               0.796813\n",
      "Sports               13.545817\n",
      "Trump Support        41.832669\n",
      "Name: value, dtype: float64\n",
      "New Hampshire\n",
      "topic\n",
      "Anti-Islam        4.444444\n",
      "Black Support    10.000000\n",
      "Crime             7.777778\n",
      "Entertainment    12.222222\n",
      "Health            3.333333\n",
      "Patriot           2.222222\n",
      "Sports           16.666667\n",
      "Trump Support    43.333333\n",
      "Name: value, dtype: float64\n",
      "North Carolina\n",
      "topic\n",
      "Anti-Islam            3.666667\n",
      "Anti-Trump            2.000000\n",
      "Black Support        18.666667\n",
      "Crime                 4.000000\n",
      "Entertainment         6.000000\n",
      "Foreign Countries     0.333333\n",
      "Health                4.333333\n",
      "Patriot               0.333333\n",
      "Sports                9.666667\n",
      "Trump Support        51.000000\n",
      "Name: value, dtype: float64\n",
      "Ohio\n",
      "topic\n",
      "Anti-Islam        1.199041\n",
      "Anti-Trump        3.357314\n",
      "Black Support    17.745803\n",
      "Crime             5.995204\n",
      "Entertainment     2.158273\n",
      "Health            6.954436\n",
      "Patriot           0.719424\n",
      "Sports           13.429257\n",
      "Trump Support    48.441247\n",
      "Name: value, dtype: float64\n",
      "Pennsylvania\n",
      "topic\n",
      "Anti-Islam            1.462226\n",
      "Anti-Trump            4.549147\n",
      "Black Support        14.134850\n",
      "Crime                 1.624695\n",
      "Entertainment        15.840780\n",
      "Foreign Countries     0.406174\n",
      "Fukushima             0.162470\n",
      "Health                4.549147\n",
      "Patriot               1.380991\n",
      "Sports               31.600325\n",
      "Trump Support        24.289196\n",
      "Name: value, dtype: float64\n",
      "Virginia\n",
      "topic\n",
      "Anti-Islam            2.238806\n",
      "Anti-Trump            1.865672\n",
      "Black Support        18.283582\n",
      "Crime                12.686567\n",
      "Entertainment         5.223881\n",
      "Foreign Countries     0.373134\n",
      "Health                6.716418\n",
      "Sports               17.910448\n",
      "Trump Support        34.701493\n",
      "Name: value, dtype: float64\n",
      "Wisconsin\n",
      "topic\n",
      "Anti-Trump        0.769231\n",
      "Black Support    13.076923\n",
      "Crime             6.153846\n",
      "Entertainment     6.153846\n",
      "Health            4.615385\n",
      "Patriot           0.769231\n",
      "Sports           26.153846\n",
      "Trump Support    42.307692\n",
      "Name: value, dtype: float64\n",
      "Texas\n",
      "topic\n",
      "Anti-Islam            2.234637\n",
      "Anti-Trump            2.048417\n",
      "Black Support        11.173184\n",
      "Crime                 4.841713\n",
      "Entertainment        28.305400\n",
      "Foreign Countries     0.186220\n",
      "Health                5.586592\n",
      "Patriot               1.862197\n",
      "Sports               15.642458\n",
      "Trump Support        28.119181\n",
      "Name: value, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# for each swing state, calculate the proportions of the different topic categories\n",
    "for state in swing_states:\n",
    "    filtered = election_month[election_month.content.str.contains(state_n_city_dict[state])].copy()\n",
    "    print(state)\n",
    "    print(filtered.groupby('topic')['value'].sum()/filtered.groupby('topic')['value'].sum().sum() * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(983, 15)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "florida.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/ada/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning:\n",
      "\n",
      "Columns (6,8,12,23,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n",
      "/anaconda3/envs/ada/lib/python3.6/site-packages/numpy/lib/arraysetops.py:472: FutureWarning:\n",
      "\n",
      "elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = pd.read_csv('../data/final_merged_tweets.csv', index_col=0)\n",
    "x['publish_date'] = pd.to_datetime(x['publish_date'])\n",
    "x = x[(x.publish_date > '2016-10-01') & (x.publish_date < '2016-11-10')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33285, 27)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada]",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
