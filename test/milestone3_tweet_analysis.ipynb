{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# interactive widget imports\n",
    "import ipywidgets as wg\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "# data handling modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# plotting imports\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly\n",
    "from plotly import tools\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "plotly.tools.set_credentials_file(username='Flavioh', api_key='GogTSHQAuhgi5p724TsF')\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "# web scraping\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# other helpers and suppress warnings\n",
    "from helpers import *\n",
    "from timeline_helpers import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", 'This pattern has match groups')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/ada/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning:\n",
      "\n",
      "Columns (6,12,23,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "\n",
    "data = pd.read_csv('../generated/FINAL_DF_WITH_TOPICS.csv', index_col=0)\n",
    "data['publish_date'] = pd.to_datetime(data['publish_date'])\n",
    "# data = data[(data.publish_date > '2016-09-01') & (data.publish_date < '2016-11-10')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>author</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>following</th>\n",
       "      <th>followers</th>\n",
       "      <th>post_type</th>\n",
       "      <th>account_category</th>\n",
       "      <th>userid</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>tweet_time</th>\n",
       "      <th>...</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>urls</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>poll_choices</th>\n",
       "      <th>follower_count</th>\n",
       "      <th>following_count</th>\n",
       "      <th>last_tweet_at</th>\n",
       "      <th>topic</th>\n",
       "      <th>topic_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#FoodPoisoning is not a joke! #Walmart #KochFa...</td>\n",
       "      <td>1D_NICOLE_</td>\n",
       "      <td>2015-11-26 22:20:00</td>\n",
       "      <td>48</td>\n",
       "      <td>40</td>\n",
       "      <td>RETWEET</td>\n",
       "      <td>Fearmonger</td>\n",
       "      <td>d077a7eaf7286285c8c406b3d5a6449b51e5ee81d26b5a...</td>\n",
       "      <td>670002488175628293</td>\n",
       "      <td>2015-11-26 22:13:00</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>[FoodPoisoning, Walmart, KochFarms]</td>\n",
       "      <td>[http://www.discusscooking.com/forums/f26/very...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107</td>\n",
       "      <td>124</td>\n",
       "      <td>2015-12-15 18:06</td>\n",
       "      <td>Trump Support</td>\n",
       "      <td>[-8.1184225  -4.818271   -2.6408563  -0.574982...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#FoodPoisoning is not a joke! #Walmart #KochFa...</td>\n",
       "      <td>BARELYBARBOZA</td>\n",
       "      <td>2015-11-26 22:34:00</td>\n",
       "      <td>50</td>\n",
       "      <td>48</td>\n",
       "      <td>RETWEET</td>\n",
       "      <td>Fearmonger</td>\n",
       "      <td>d077a7eaf7286285c8c406b3d5a6449b51e5ee81d26b5a...</td>\n",
       "      <td>670002488175628293</td>\n",
       "      <td>2015-11-26 22:13:00</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>[FoodPoisoning, Walmart, KochFarms]</td>\n",
       "      <td>[http://www.discusscooking.com/forums/f26/very...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107</td>\n",
       "      <td>124</td>\n",
       "      <td>2015-12-15 18:06</td>\n",
       "      <td>Trump Support</td>\n",
       "      <td>[-8.1184225  -4.818271   -2.6408563  -0.574982...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#FoodPoisoning is not a joke! #Walmart #KochFa...</td>\n",
       "      <td>D_ANDRE_AUSTIN_</td>\n",
       "      <td>2015-11-26 22:20:00</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>RETWEET</td>\n",
       "      <td>Fearmonger</td>\n",
       "      <td>d077a7eaf7286285c8c406b3d5a6449b51e5ee81d26b5a...</td>\n",
       "      <td>670002488175628293</td>\n",
       "      <td>2015-11-26 22:13:00</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>[FoodPoisoning, Walmart, KochFarms]</td>\n",
       "      <td>[http://www.discusscooking.com/forums/f26/very...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107</td>\n",
       "      <td>124</td>\n",
       "      <td>2015-12-15 18:06</td>\n",
       "      <td>Trump Support</td>\n",
       "      <td>[-8.1184225  -4.818271   -2.6408563  -0.574982...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#FoodPoisoning is not a joke! #Walmart #KochFa...</td>\n",
       "      <td>ERTMANGRETA</td>\n",
       "      <td>2015-11-26 22:20:00</td>\n",
       "      <td>57</td>\n",
       "      <td>50</td>\n",
       "      <td>RETWEET</td>\n",
       "      <td>RightTroll</td>\n",
       "      <td>d077a7eaf7286285c8c406b3d5a6449b51e5ee81d26b5a...</td>\n",
       "      <td>670002488175628293</td>\n",
       "      <td>2015-11-26 22:13:00</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>[FoodPoisoning, Walmart, KochFarms]</td>\n",
       "      <td>[http://www.discusscooking.com/forums/f26/very...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107</td>\n",
       "      <td>124</td>\n",
       "      <td>2015-12-15 18:06</td>\n",
       "      <td>Trump Support</td>\n",
       "      <td>[-8.1184225  -4.818271   -2.6408563  -0.574982...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#FoodPoisoning is not a joke! #Walmart #KochFa...</td>\n",
       "      <td>FREDYTHECREATOR</td>\n",
       "      <td>2015-11-26 22:34:00</td>\n",
       "      <td>65</td>\n",
       "      <td>50</td>\n",
       "      <td>RETWEET</td>\n",
       "      <td>Fearmonger</td>\n",
       "      <td>d077a7eaf7286285c8c406b3d5a6449b51e5ee81d26b5a...</td>\n",
       "      <td>670002488175628293</td>\n",
       "      <td>2015-11-26 22:13:00</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>[FoodPoisoning, Walmart, KochFarms]</td>\n",
       "      <td>[http://www.discusscooking.com/forums/f26/very...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107</td>\n",
       "      <td>124</td>\n",
       "      <td>2015-12-15 18:06</td>\n",
       "      <td>Trump Support</td>\n",
       "      <td>[-8.1184225  -4.818271   -2.6408563  -0.574982...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text           author  \\\n",
       "0  #FoodPoisoning is not a joke! #Walmart #KochFa...       1D_NICOLE_   \n",
       "1  #FoodPoisoning is not a joke! #Walmart #KochFa...    BARELYBARBOZA   \n",
       "2  #FoodPoisoning is not a joke! #Walmart #KochFa...  D_ANDRE_AUSTIN_   \n",
       "3  #FoodPoisoning is not a joke! #Walmart #KochFa...      ERTMANGRETA   \n",
       "4  #FoodPoisoning is not a joke! #Walmart #KochFa...  FREDYTHECREATOR   \n",
       "\n",
       "         publish_date  following  followers post_type account_category  \\\n",
       "0 2015-11-26 22:20:00         48         40   RETWEET       Fearmonger   \n",
       "1 2015-11-26 22:34:00         50         48   RETWEET       Fearmonger   \n",
       "2 2015-11-26 22:20:00          0         49   RETWEET       Fearmonger   \n",
       "3 2015-11-26 22:20:00         57         50   RETWEET       RightTroll   \n",
       "4 2015-11-26 22:34:00         65         50   RETWEET       Fearmonger   \n",
       "\n",
       "                                              userid             tweetid  \\\n",
       "0  d077a7eaf7286285c8c406b3d5a6449b51e5ee81d26b5a...  670002488175628293   \n",
       "1  d077a7eaf7286285c8c406b3d5a6449b51e5ee81d26b5a...  670002488175628293   \n",
       "2  d077a7eaf7286285c8c406b3d5a6449b51e5ee81d26b5a...  670002488175628293   \n",
       "3  d077a7eaf7286285c8c406b3d5a6449b51e5ee81d26b5a...  670002488175628293   \n",
       "4  d077a7eaf7286285c8c406b3d5a6449b51e5ee81d26b5a...  670002488175628293   \n",
       "\n",
       "            tweet_time                        ...                          \\\n",
       "0  2015-11-26 22:13:00                        ...                           \n",
       "1  2015-11-26 22:13:00                        ...                           \n",
       "2  2015-11-26 22:13:00                        ...                           \n",
       "3  2015-11-26 22:13:00                        ...                           \n",
       "4  2015-11-26 22:13:00                        ...                           \n",
       "\n",
       "   retweet_count                             hashtags  \\\n",
       "0             15  [FoodPoisoning, Walmart, KochFarms]   \n",
       "1             15  [FoodPoisoning, Walmart, KochFarms]   \n",
       "2             15  [FoodPoisoning, Walmart, KochFarms]   \n",
       "3             15  [FoodPoisoning, Walmart, KochFarms]   \n",
       "4             15  [FoodPoisoning, Walmart, KochFarms]   \n",
       "\n",
       "                                                urls  user_mentions  \\\n",
       "0  [http://www.discusscooking.com/forums/f26/very...            NaN   \n",
       "1  [http://www.discusscooking.com/forums/f26/very...            NaN   \n",
       "2  [http://www.discusscooking.com/forums/f26/very...            NaN   \n",
       "3  [http://www.discusscooking.com/forums/f26/very...            NaN   \n",
       "4  [http://www.discusscooking.com/forums/f26/very...            NaN   \n",
       "\n",
       "   poll_choices  follower_count  following_count     last_tweet_at  \\\n",
       "0           NaN             107              124  2015-12-15 18:06   \n",
       "1           NaN             107              124  2015-12-15 18:06   \n",
       "2           NaN             107              124  2015-12-15 18:06   \n",
       "3           NaN             107              124  2015-12-15 18:06   \n",
       "4           NaN             107              124  2015-12-15 18:06   \n",
       "\n",
       "           topic                                       topic_scores  \n",
       "0  Trump Support  [-8.1184225  -4.818271   -2.6408563  -0.574982...  \n",
       "1  Trump Support  [-8.1184225  -4.818271   -2.6408563  -0.574982...  \n",
       "2  Trump Support  [-8.1184225  -4.818271   -2.6408563  -0.574982...  \n",
       "3  Trump Support  [-8.1184225  -4.818271   -2.6408563  -0.574982...  \n",
       "4  Trump Support  [-8.1184225  -4.818271   -2.6408563  -0.574982...  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filtered = data[['publish_date', 'followers', 'following', 'author', 'like_count', 'topic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Black Support        155980\n",
       "Sports               123092\n",
       "Trump Support        122362\n",
       "Entertainment         92535\n",
       "Health                44969\n",
       "Foreign Countries     27271\n",
       "Crime                 22443\n",
       "Anti-Islam            19843\n",
       "Anti-Trump            17311\n",
       "Patriot               11658\n",
       "Fukushima               582\n",
       "Name: topic, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_filtered.topic.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "def count_topic(topic, df):\n",
    "    \"\"\"The function takes in a language as a DEFINE_string\n",
    "    and goes through a dataframe that has one column named\n",
    "    topic and another one that has publish_date. It then\n",
    "    groups the tweets by month and returns the sum of the\n",
    "    tweets during the time period\"\"\"\n",
    "\n",
    "    filt = df[df.topic == topic].copy()\n",
    "    filt['topic_num'] = filt.topic.map({topic:1})\n",
    "    return filt.groupby(pd.Grouper(key='publish_date', freq='1D')).sum()\n",
    "\n",
    "def trace_generator_topic(topic_df):\n",
    "    \"\"\"This function generates the data that will be used\n",
    "    as input for the iplot function. It prepares the labels\n",
    "    from the index\"\"\"\n",
    "    data = []\n",
    "    for topic in topic_df.topic.value_counts().index.values:\n",
    "        filtered=count_topic(topic, topic_df)\n",
    "        strd = pd.Series(filtered.index.strftime('%Y-%m-%d %H-%M-%S'))\n",
    "        xlabels = list(strd.apply(lambda x: x[0:10]))\n",
    "        trace = go.Scatter(x=xlabels,\n",
    "                            y=filtered.topic_num.values,\n",
    "                            fill='tozeroy',\n",
    "                            mode= 'none',\n",
    "                            name=topic)\n",
    "        data.append(trace)\n",
    "\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~Flavioh/84.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = trace_generator_topic(data_filtered)\n",
    "layout = do_layout('Date', 'Number of Tweets', 'Topic as a Function of Time')\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examination of Top Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract top 10 posting authors\n",
    "top_authors = data_filtered.author.value_counts()[0:10]\n",
    "\n",
    "# Filter data frame for them\n",
    "###### testing with screamymonkey\n",
    "\n",
    "test = data_filtered[data_filtered.author.isin(top_authors.index.values)]\n",
    "# test = data_filtered[data_filtered.author == 'WORLDOFHASHTAGS']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SCREAMYMONKEY      41908\n",
       "MILWAUKEEVOICE     38814\n",
       "PHOENIXDAILYNEW    33211\n",
       "ROOMOFRUMOR        28642\n",
       "TODAYPITTSBURGH    22177\n",
       "SEATTLE_POST       21111\n",
       "KANSASDAILYNEWS    17490\n",
       "DAILYSANJOSE       14070\n",
       "DAILYSANFRAN       13812\n",
       "EXQUOTE            11320\n",
       "Name: author, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~Flavioh/86.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data1 = trace_generator_topic(test)\n",
    "layout = do_layout('Date', 'Number of Tweets', 'Topic for Top 10 Authors Over Time')\n",
    "fig = go.Figure(data=data1, layout=layout)\n",
    "py.iplot(fig, filename='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/ada/lib/python3.6/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]\n",
      "[ (2,1) x2,y2 ]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~Flavioh/86.embed\" height=\"600px\" width=\"800px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out follower counts for top 10 hashtaggers\n",
    "\n",
    "data = []\n",
    "data.append(data)\n",
    "\n",
    "group_followers = test.groupby([pd.Grouper(key='publish_date', freq='1D'), 'author'])['followers'].max().groupby(level=0).sum()\n",
    "\n",
    "######\n",
    "\n",
    "test['tweet_counts'] = np.ones(test.shape[0])\n",
    "\n",
    "group_following =test.groupby([pd.Grouper(key='publish_date', freq='1D'),\n",
    "                                 'author'])['following'].max().groupby(level=0).sum()\n",
    "group_authors_time = pd.DataFrame({'followers': group_followers.values,\n",
    "                                   'following': group_following.values},\n",
    "                                  index=group_followers.index.values)\n",
    "\n",
    " \n",
    "# group by month\n",
    "general_timeline = test.groupby(pd.Grouper(key='publish_date', freq='1D')).sum()\n",
    "# construct labels\n",
    "xlabels = list(pd.Series(group_authors_time.index.strftime(\n",
    "    '%Y-%m-%d %H-%M-%S')).apply(lambda x: x[0:10]))\n",
    "\n",
    "for col in group_authors_time:\n",
    "    filtered = group_authors_time[col].copy()\n",
    "    trace = go.Scatter(x=xlabels, y=filtered.values, name=col, \n",
    "                       fill='tozeroy', mode='lines')\n",
    "    data.append(trace)\n",
    "\n",
    "filtered = general_timeline['tweet_counts'].copy()\n",
    "trace=go.Scatter(x=xlabels, y=filtered.values, marker = {'color' : '#00AA00'}, name='Tweet Counts', fill='tozeroy', mode='lines')\n",
    "data.append(trace)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create plots for following, followers, updates, tweet_counts\n",
    "\n",
    "fig = tools.make_subplots(rows=3, cols=1)\n",
    "fig.append_trace(data[0], 1, 1)\n",
    "fig.append_trace(data[1], 2, 1)\n",
    "fig.append_trace(data[2], 2, 1)\n",
    "fig.append_trace(data[3], 3, 1)\n",
    "\n",
    "fig['layout'].update(height=600, width=800, title='General Trends Across Time')\n",
    "py.iplot(fig, filename='y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(group_followers.values)\n",
    "plt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Swing State Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "\n",
    "# Scrape wikipedia table for american cities and states\n",
    "website = requests.get('https://en.wikipedia.org/wiki/List_of_largest_cities_of_U.S._states_and_territories_by_population').text\n",
    "soup = BeautifulSoup(website,'html.parser')\n",
    "\n",
    "My_table = soup.find('table',{'class':'wikitable sortable'})\n",
    "\n",
    "links = My_table.find_all('a')\n",
    "\n",
    "places = []\n",
    "for link in links:\n",
    "    places.append(link.get('title'))\n",
    "    \n",
    "city_clean = list(filter(None.__ne__, places)) # Drop None values\n",
    "cities = {}\n",
    "\n",
    "\n",
    "for entry in city_clean:\n",
    "    split=entry.split(', ')\n",
    "    if len(split) == 1:\n",
    "        cities[split[0]] = []\n",
    "    else:\n",
    "        if split[1] in cities.keys():\n",
    "            cities[split[1]].append(split[0]) \n",
    "state_n_city = []\n",
    "for state in cities.keys():\n",
    "    state_list = []\n",
    "    state_cities = cities[state]\n",
    "    for city in state_cities:\n",
    "        state_list.append(city + '|' + city.lower())\n",
    "    state_list.append(state + '|' + state.lower())\n",
    "    state_list = '|'.join(state_list)\n",
    "    state_n_city.append([state, state_list])\n",
    "    \n",
    "state_n_city_dict = {}\n",
    "for state in state_n_city:\n",
    "    state_n_city_dict[state[0]] = state[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada]",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
