{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "# interactive widget imports\n",
    "import ipywidgets as wg\n",
    "from IPython.display import display\n",
    "\n",
    "# data handling modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# plotting imports\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly\n",
    "plotly.tools.set_credentials_file(username='halima.schede', api_key='0BXIz4i3MnnYF4z7QhA0')\n",
    "\n",
    "# web scraping\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# other helpers and suppress warnings\n",
    "from helpers import *\n",
    "from timeline_helpers import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", 'This pattern has match groups')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "tweets1 = pd.read_csv(access_folder('data') + 'IRAhandle_tweets_1.csv')\n",
    "tweets2 = pd.read_csv(access_folder('data') + 'IRAhandle_tweets_2.csv')\n",
    "tweets3 = pd.read_csv(access_folder('data') + 'IRAhandle_tweets_3.csv')\n",
    "tweets4 = pd.read_csv(access_folder('data') + 'IRAhandle_tweets_4.csv')\n",
    "tweets5 = pd.read_csv(access_folder('data') + 'IRAhandle_tweets_5.csv')\n",
    "tweets6 = pd.read_csv(access_folder('data') + 'IRAhandle_tweets_6.csv')\n",
    "tweets7 = pd.read_csv(access_folder('data') + 'IRAhandle_tweets_7.csv')\n",
    "tweets8 = pd.read_csv(access_folder('data') + 'IRAhandle_tweets_8.csv')\n",
    "tweets9 = pd.read_csv(access_folder('data') + 'IRAhandle_tweets_9.csv')\n",
    "\n",
    "\n",
    "\n",
    "tweets = pd.concat([tweets1, tweets2, tweets3, tweets4, tweets5, tweets6, tweets7, tweets8, tweets9], axis=0, join='outer', join_axes=None, ignore_index=False,\n",
    "          keys=None, levels=None, names=None, verify_integrity=False,\n",
    "          copy=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.dropna(how='any', axis=0, inplace=True)\n",
    "tweets['publish_date'] = pd.to_datetime(tweets['publish_date'], format='%m/%d/%Y %H:%M')\n",
    "# Since the values of tweets are minimal before 2015 filter dataframe\n",
    "tweets_processed = tweets[tweets.publish_date > '2015']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape wikipedia table for american cities and states\n",
    "website = requests.get('https://simple.wikipedia.org/wiki/List_of_United_States_cities_by_population').text\n",
    "soup = BeautifulSoup(website,'html5lib')\n",
    "My_table = soup.find('table',{'class':'wikitable sortable'})\n",
    "links = My_table.find_all('a')\n",
    "\n",
    "places = []\n",
    "for link in links:\n",
    "    places.append(link.get('title'))\n",
    "    \n",
    "    \n",
    "city_clean = list(filter(None.__ne__, places)) # Drop None values\n",
    "\n",
    "# Initialize lists for city and state names\n",
    "cities = []\n",
    "states = []\n",
    "for x in range(0, len(city_clean)):\n",
    "    if x%2 == 0:\n",
    "        cities.append(city_clean[x].split(',')[0]) # Retrieve only city name, not state\n",
    "    else:\n",
    "        states.append(city_clean[x]) # append state name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for english tweets\n",
    "tweets_english = tweets_processed[tweets_processed.language == 'English']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count occurences of tweets for names in cities, and names in states\n",
    "tweets_city = list(map(lambda x: tweets_english.content.str.contains(x).sum(), cities))\n",
    "tweets_state = list(map(lambda x: tweets_english.content.str.contains(x).sum(), states))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_counts = pd.DataFrame(data={'city' : cities, 'city_counts':tweets_city})\n",
    "state_counts = pd.DataFrame(data={'state' : states, 'state_counts':tweets_state})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_states = pd.concat([city_counts, state_counts], axis=1)\n",
    "df_citycounts_state = cities_states[['city', 'city_counts', 'state']]\n",
    "grouped_state = df_citycounts_state.groupby('state')['city_counts'].sum()\n",
    "ordered_state_city = grouped_state.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping by State Name Occurence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_state = state_counts.drop_duplicates().sort_values(by='state').reset_index(drop=True)\n",
    "ordered_state['code'] = pd.Series(['AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'FL',\n",
    "                                  'GA', 'HI','ID','IL','IN','IA','KS','KY','LA','MD','MA',\n",
    "                                  'MI','MN','MS','MO','MT','NE','NV','NH','NJ','NM','NY',\n",
    "                                  'NC','ND','OH','OK','OR','PA','RI','SC','SD','TN','TX',\n",
    "                                  'UT','VA','WA','WA','WI'])\n",
    "ordered_state.drop(44, inplace=True)\n",
    "ordered_state.loc[44] = ['Wyoming', 0, 'WY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~halima.schede/8.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [ dict(\n",
    "        type='choropleth',\n",
    "        colorscale = 'Bluered',\n",
    "        autocolorscale = False,\n",
    "        locations = ordered_state['code'],\n",
    "        z = ordered_state['state_counts'].astype(float).apply(lambda x: np.log(x)),\n",
    "        locationmode = 'USA-states',\n",
    "        text = ordered_state['state'],\n",
    "        marker = dict(\n",
    "            line = dict (\n",
    "                color = 'rgb(255,255,255)',\n",
    "                width = 2\n",
    "            ) ),\n",
    "        colorbar = dict(\n",
    "            title = \"Number of Tweets (Log-value)\")\n",
    "        ) ]\n",
    "\n",
    "layout = dict(\n",
    "        title = 'States Mentioned in Tweets',\n",
    "        geo = dict(\n",
    "            scope='usa',\n",
    "            projection=dict( type='albers usa' ),\n",
    "            showlakes = True,\n",
    "            lakecolor = 'rgb(255, 255, 255)'),\n",
    "             )\n",
    "    \n",
    "fig = dict( data=data, layout=layout )\n",
    "py.iplot( fig, filename='d3-cloropleth-map' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping by City Name Occurence by State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_state_city['code'] = pd.Series(['AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'FL',\n",
    "                                  'GA', 'HI','ID','IL','IN','IA','KS','KY','LA','MD','MA',\n",
    "                                  'MI','MN','MS','MO','MT','NE','NV','NH','NJ','NM','NY',\n",
    "                                  'NC','ND','OH','OK','OR','PA','RI','SC','SD','TN','TX',\n",
    "                                  'UT','VA','WA','WA','WI'])\n",
    "ordered_state_city.drop(index=44, inplace=True)\n",
    "ordered_state_city.loc[44] = ['Wyoming', 0, 'WY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [ dict(\n",
    "        type='choropleth',\n",
    "        colorscale = 'Bluered',\n",
    "        autocolorscale = False,\n",
    "        locations = ordered_state_city['code'],\n",
    "        z = ordered_state_city['city_counts'].astype(float).apply(lambda x: np.log(x)),\n",
    "        locationmode = 'USA-states',\n",
    "        text = ordered_state_city['state'],\n",
    "        marker = dict(\n",
    "            line = dict (\n",
    "                color = 'rgb(255,255,255)',\n",
    "                width = 2\n",
    "            ) ),\n",
    "        colorbar = dict(\n",
    "            title = \"Number of Tweets\")\n",
    "        ) ]\n",
    "\n",
    "layout = dict(\n",
    "        title = 'Cities Mentioned in Tweets by State',\n",
    "        geo = dict(\n",
    "            scope='usa',\n",
    "            projection=dict( type='albers usa' ),\n",
    "            showlakes = True,\n",
    "            lakecolor = 'rgb(255, 255, 255)'),\n",
    "             )\n",
    "    \n",
    "fig = dict( data=data, layout=layout )\n",
    "py.iplot( fig, filename='d3-cloropleth-map' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timeline analysis of state names in tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_plot = ordered_state.sort_values('state_counts', ascending=False).state.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_states = []\n",
    "for i in states_plot:\n",
    "    plot_states.append(extract_states(i, tweets_english))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~halima.schede/10.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "for ind, i in enumerate(states_plot[0:10]):\n",
    "    strd = pd.Series(plot_states[ind].index.strftime('%Y-%m-%d %H-%M-%S'))\n",
    "    xlabels = list(strd.apply(lambda x: x[0:7]))\n",
    "    trace = go.Scatter(x = xlabels, y = plot_states[ind].values, mode = 'lines', name=i,\n",
    "                      groupnorm='percent')\n",
    "    data.append(trace)\n",
    "\n",
    "layout = do_layout('Date', 'Number of Tweets', 'State Mentions over Time')\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='line-mode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query by User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24fde1965a2745d6a3e31e063db447e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='Query string')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Querying for string defined by user\n",
    "\n",
    "query = wg.Text(value='Query string')\n",
    "display(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~halima.schede/12.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_df = extract_states(query.get_interact_value(), tweets_english)\n",
    "strd = pd.Series(query_df.index.strftime('%Y-%m-%d %H-%M-%S'))\n",
    "xlabels = list(strd.apply(lambda x: x[0:7]))\n",
    "trace = go.Scatter(x = xlabels, y = query_df.values, mode = 'lines',\n",
    "                   name=query.get_interact_value(),\n",
    "                   groupnorm='percent')\n",
    "data = []\n",
    "data.append(trace)\n",
    "layout = do_layout('Date', 'Number of Tweets', '{} Mentions over Time'.format(\n",
    "    query.get_interact_value()))\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='query')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada]",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
